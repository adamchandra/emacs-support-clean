* CONFIG
*** org-mode configuration
   :HIDDEN:
#+COLUMNS: %38ITEM(Details) %TAGS(Context) %7TODO(To Do) %5Effort(Time){:} %6CLOCKSUM{Total}
#+PROPERTY: Effort_ALL 0 0:10 0:20 0:30 1:00 2:00 3:00 4:00 8:00
   :END:


* Put this document up on the web
* Use nosy.py to autocommit files every few minutes

*** creating a new hg repo on iesl
    :MORE:
    cd /m/iesl/data2/home/hg/repositories
    sudo mkdir new-project-name
    cd heritrix-profiles/
    sudo hg init
    sudo touch .hgignore
    sudo hg addr
    sudo hg commit -m 'created'
    ..
    sudo chown -R hg heritrix-profiles/
    sudo chgrp -R hg heritrix-profiles/
    :END:

*** autostarting a service on unix
    /sbin/chkconfig --list
    /sbin/chkconfig --add httpd # for example

*** Maven notes
    http://www.sonatype.com/people/2009/01/maven-continuous-integration-best-practices/



*** Network configuration to get ubuntu 11.10 to see the the port forwarded
    #+BEGIN_EXAMPLE
    http://www.sonatype.com/people/2009/01/maven-continuous-integration-best-practices/
    connection from sendak
      Edit  /etc/NetworkManager/NetworkManager.conf :
      After: [ifupdown],
      
      change managed=false to managed=true
      
      Then restart the network as follows
      # service network-manager stop
      # service network-manager start
    
    #+END_EXAMPLE

[ ] J. Aitchison. The Statistical Analysis of Compositional Data. Chapman & Hall, 1986. 
[ ] D. M. Blei and J. D. Lafferty. Dynamic topic models. In ICML, 2006. 
[ ] D. M. Blei and J. D. Lafferty. A correlated topic model of Science. AAS, 1(1):17–35, 2007. 
[ ] L. Devroye. Random variate generation in one line of code. In Winter Simulation Conference, 1996. 
[ ] L. Dietz, S. Bickel, and T. Scheffer. Unsupervised prediction of citation influences. In ICML, 2007. 
[ ] T. L. Griffiths and M. Steyvers. Finding scientific topics. PNAS, 101(suppl. 1):5228–5235, 2004. 
[ ] P. C. Groenewald and L. Mokgatlhe. Bayesian computation for logistic regression. Computational Statistics and Data Analysis, 48:857–868, 2005. 
[ ] A. Gruber, M. Rosen-Zvi, and Y.Weiss. Latent topic models for hypertext. In UAI, 2008. 
[ ] C. C. Holmes and L. Held. Bayesian auxiliary variable models for binary and multinomial regression. Bayesian Analysis, 1(1):145–168, 2006.
[ ] W. Li and A. McCallum. Pachinko allocation: DAG-structured mixture models of topic correlations. In ICML, 2006. 
[ ] Q. Mei, D. Cai, D. Zhang, and C. Zhai. Topic modeling with network regularization. In WWW, 2008. 
[ ] R. Nallapati andW. Cohen. Link-PLSA-LDA: A new unsupervised model for topics and influence of blogs. In ICWSM, 2008. 
[ ] H. Rue and L. Held. Gaussian Markov Random Fields. Chapman & Hall/CRC, 2005.



-------------------------------------


Representations and Linguistic Data ........................................1
1.1 Sequential Prediction .................................................... 
2 1.2 Sequence Segmentation ................................................. 
4 1.3 Word Classes and Sequence Labeling ...................................... 
5 1.3.1 Morphological Disambiguation ..................................... 
6 1.3.2 Chunking ....................................................... 
7 1.4 Syntax ................................................................ 
9 1.5 Semantics ............................................................ 
11 1.6 Coreference Resolution ................................................. 
14 1.7 Sentiment Analysis .................................................... 
16 1.8 Discourse ............................................................. 
16 1.9 Alignment ............................................................ 
17 1.10 Text-to-TextTransformations ............................................ 


23 2.2 Five Views of Decoding ................................................ 
24 2.2.1 Probabilistic Graphical Models .................................... 
27 2.2.2 Polytopes ....................................................... 
31 2.2.3 Parsing with Grammars .......................................... 
37 2.2.4 Graphs and Hypergraphs ......................................... 
39 2.2.5 Weighted Logic Programs ........................................ 


-------------------------------------------


Graph DB / Dist Keystore / RelationalDB 

- 


filesystem: 
<xml/>..


BIOLU: 

[ ] J. Aitchison. The Statistical Analysis of Compositional Data. Chapman & Hall, 1986. 
Bil.U..Biiiiiiil..

stored as: string + checksum + list of BIO-xx encoded as numbers

e.g., 
[ ] J. Aitchison. The Statistical Analysis of Compositional Data. Chapman & Hall, 1986. 
1230450455555556 etc..


....or....

graph db: 

[ ] J. Aitchison. The Statistical Analysis of Compositional Data. Chapman & Hall, 1986. 
                      ^---------^-^------^
                      1         2 3      4

^ = node(type="anchor", index=23)
    node(type="anchor", index=41)
    edge(n1, n2, POS/NNP
    edge(n3, n4, POS/NP
    edge(n1, n4, POS/PHRASE/NNP   
    edge(n1, n4, ER/Entity            # this is actually now a node??


document ---> paragraph ---> sentence ---> word


-------- reference
## [23] J. Aitchison. The Statistical Analysis of Compositional Data. Chapman & Hall, 1986. 


## tokens: "[23]{0-4}" "J.{5-7}" "Aitchison." "The" "Statistical" 
                                      |
                                     NNP


parse nyt data
xml -> text mentions
tokenize into para/sent/word
POS tag
NER tag
search phrases



Someone (I forget who) recently wrote (I forget where): "DI is just
socially acceptable global variables." This is mostly true -- I say
mostly because I think the adverb "globally" is redundant and
misleading. That is to say, there is no such thing as a global variable.
All variables are scoped to some context and it is the extent of this
context that is a measure of detriment. This is why you hear people
talking about "keeping their side-effects local." This wishful-thinking
almost never eventuates because side-effects are pervasive. I am
side-tracking here, but going back to the original topic briefly.

In the absence of my awareness of your constraints, I can point out what
it is that most people want when they think they want DI, and in fact,
do not, ever (it is one of many forms of masochism in programming --
bare with me).

First, let us consider a general Scala program and generalise it. This
is just an arbitrary program -- I am trying to make it as convoluted as
possible so that you can go back to a real program and apply the same
reasoning. Importantly, this program is side-effect free at this point.

val a = e1
val b = e2(a)
val c = e3(a, b)
val d = e2(b)

OK, now I am going to generalise it by running the same program, but in
a for-comprehension. We do this by following these rules:
1) Remove the 'val' keyword
2) The = symbol becomes <-
3) We wrap the program in for and yield

I am going to create a data type that simply wraps a value and provides
flatMap and map methods so I can do this:

case class Id[A](i: A) {
def map[B](f: A => B) = Id(f(i))
def flatMap[B](f: A => Id[B]) = f(i)
}

...and since I don't want to explicitly wrap/unwrap my values with Id, I
am going to provide an implicit for in and out:

object Id {
implicit def IdIn[A](a: A) = Id(a)
implicit def IdOut[A](a: Id[A]) = a.i
}

OK, so now let's translate our program:

for {
a <- e1
b <- e2(a)
c <- e3(a, b)
d <- e2(b)
} yield d

Now that you accept that any program can be written this way, let us
step away for a moment and address the idea of DI. There are usually two
variations on DI:
1) The "configuration" (or context) is done and the application must
start by first initialising this context, then the application may run.
The application then reads from the configuration during run-time but
does not modify it. If this order is altered, you end up with a broken
program. A "DI" container attempts to promise you that no such thing
will occur -- this is essentially what the selling point is.

This dependency on explicit execution order is directly anti-thetical to
the functional programming thesis. This is a consequence of there being
a widely-scoped variable that kind-of pretends otherwise.

If you turn your head just a little, you can see this is a somewhat
degenerate notion of what is called "uniqueness typing." I digress.

2) Same as above, however, not only is the application permitted to read
the configuration, but it is also permitted to *write* to it. This means
that the application depends on *more* explicit execution order and the
possibility of bugs increases even more.

Imagine if I said, "you know what, turn all that DI stuff off, we are
going to initialise our values up front and pass them all the way
through the application." You would surely protest, "but that is so
clumsy!" and you'd be right, but only at first glance.

You see, there is a way to pass these values through quite neatly and
no, this is not using Scala's implicit keyword (which is insufficient),
this is something else. OK, so let's first start by thinking about case
1) above where the application only has read access to some context. I
will name this context, "Context", it is a data type that is
somewhere-or-other that we would like to pass through our application --
but no writes to it. I'm sure you can imagine what Context would really
be -- feel free to make it up for the use-case.

So, our values that were once mere values, are now computed as if they
have access to a Context. We can denote this with a data type:

case class ComputedWithContext[A](cx: Context => A)

So we now have "first-class" values computed with a Context, rather than
being mere values. We can now create these by accessing a Context "as if
it were passed" -- that is to say, although we don't yet have a Context,
we may create values that access that Context (when it is eventually
passed) by wrapping a function (or a trait if you prefer).

This is simple and straight-forward enough. But watch this:

case class ComputedWithContext[A](cx: Context => A) {
  def map[B](f: A => B): ComputedWithContext[B] = 
      ComputedWithContext(f compose cx)

  def flatMap[B](f: A => ComputedWithContext[B]): ComputedWithContext[B] = 
      ComputedWithContext(c => f(cx(c)) cx c)
}

We see here that ComputedWithContext happens to have pretty handy map
and flatMap methods. What can we do with them?

OK, so suppose our program above is a little different to the original
in that actually, our expressions (e1, e2 and e3) require a Context, so
each of them becomes become ComputedWithContext[T] where previously they
were just the type T (they may be all different values for T or same --
no matter).

For example, e1 may have been an Int where now it is a
ComputedWithContext[Int] and e2 may have been a String where now it is a
ComputedWithContext[String]. You get the point.

Here is how our program looks:

for {
a <- e1
b <- e2(a)
c <- e3(a, b)
d <- e2(b)
} yield d

This is precisely the same program syntax. The type of this expression
is ComputedWithContext[T] where the type T depends on the value d. In
other words, we may pass a Context in to this value and it gets
"threaded" through our program and our program *doesn't change* if we
write it in this general form. We may "stack these layers" on top of
what started as Id and our program remains unaltered. The "theory" of
doing this is quite involved, mostly because it is kick-arse interesting
and we could talk about it some time, but that's another story!

Importantly, there are no variables here. Not one and not a pretend
value that is actually a variable at application time (which I'm sure
you've been reminded of more than once when using DI).

So, this is how we deal with passing read-only context through our
application:
* without being clumsy by explicitly passing it
* being quite efficient and readable in fact!
* without using variables that leads to program bugs and difficulty
reading and debugging code

How do we deal with read and write values (case 2)? Well, we need a new
different data type for that:

case class WriteWithContext[A](cx: Context => (A, Context))

Notice how this is the same data type as before except the function can
now produce a *new* Context as well as the computed value (paired). This
is to say, we may "modify" the Context as it is threaded through. But
what about map and flatMap, can we write those? Of course:

case class WriteWithContext[A](cx: Context => (A, Context)) {
def map[B](f: A => B): WriteWithContext[B] = WriteWithContext(c => val
(a, cc) = cx(c); (f(a), cc))
def flatMap[B](f: A => WriteWithContext[B]): WriteWithContext[B] =
WriteWithContext(c => { val (a, cc) = cx(c); f(a) cx cc })
}

Don't get too carried away with reading those methods, but just note
that flatMap "threads the Context through whatever the function is,
which may be modifying it."

OK, so now if we suppose that our expressions (e1, e2, e3) actually had
access to the Context, but were also able to "modify" it by returning a
new Context (or just leaving it alone, for which there is library
support of course), then our program would look like this:

for {
a <- e1
b <- e2(a)
c <- e3(a, b)
d <- e2(b)
} yield d

Yep, exactly the same as before. So now we have a value that we can pass
in a Context and it is threaded through the program, potentially
"modifying" the Context as it is threaded through and we get a value and
the resulting Context at the end. We may wish to drop either of these --
in practice, the Context often gets dropped, since it was only need to
compute the value -- and of course, there is library support for that.

So hopefully now you see that DI can be replaced by a superior
programming model, at least for this example, and I promise, for any
example. We just have to come to terms with a few data types and
abstractions and we can kick that baby to the gutter where it belongs.

Hope that helps!


