* rexa reboot notes

* CONFIG
*** org-mode configuration
   :HIDDEN:
   :END:


* Browser plugin which identifies all citations/authors/institutions on a page and links them to the rexa system
*** Authors can annotate the span of a reference to pull in rexa formatting for all viewers
    Citations on a page will look like rexa citations, w/links, hovers, etc

*** Any client browser can use a plugin to allow: 
    highlight and submit a mention as citation, author, pub-page, venue/inst
    


* REMEMBER TO TURN ON GIT AUTOCOMMIT!!!!
  - Under supervisord control now...
  - watch '(git-select m | xargs -i git commit {} -m "autocommit")'

* Figure out a way to have .hg/.git files under different user, but hg/git commands work seamlessly

******* Rexa codebase refactoring
********* Overview
          - Project Structure
            + CorServe
            + virtualenv-sandbox:
              + rexa-pstotext-ve : pstotext, textmill, gamut
              + ipython-ve : supervisor, ipython configs
              + rexa-back : old rexa common codebase
              + (later) ocropus/gamera/PIL

            + rexa-front : web front end
            + rexo (?? change this) rexa-coref ?

********* Tasks
          - [ ] Put the current rexa front under supervisor, to better facilitate restarts on server reboot
          - [ ] Document the architecture of the Rexa system
          - [ ] Redesign the Rexa logo (use graphical model notation, perhaps?)

====================================================================================================
******* Feature lists derived from various Bibtex/Research paper management systems
        Zotero, Mendeley, CiteULike, EndNote, 
        Qiqqa (window only)
        Papers: http://www.mekentosj.com/papers/

********* Features
          - PDF Annotations
          - Annotations Report
          - Text Highlighting
          - Comments
          - Tags
          - Hierarchical Tags
          - PDF text search
          - Built-in full text indexed search
          - Automatic OCR of images
          - Web-hosted Library
          - Syncing across multiple machines
          - Access from multiple devices
          - Alternate non-browser-based UI
          - Search over PubMed/Google Scholar/...
          - BibTeX and LaTeX support
          - Word 2007 and 2010 support
          - Search over Authors
          - Keyword cloud
          - Auto Tags
          - Visually map links between documents



====================================================================================================

******* Spider/Fetcher
********* Overview
          + Download files to local filesystem, using standard directory mirror plugin
          + At set intervals, push new corpora to corserve for processing
          + Includes web front-end for visualization, search and interaction with spider
            Ultimately, will allow users to submit URLs, retrieve documents from local cache, get html
            page contexts.

          + Spiders are currently housed on:
            - vinci7/data2, 3

********* Tasks
          - [ ] dump out mongofs pdfs to actual filesystem

********* Feature wishlist
          + Constantly running spider(s)
          + Web front end to monitor spider activity
          + Automatically push new papers into corserve corpus
          + http-domain connectivity graph with paper counts per domain
          + Visualizer for available disk space on shards and across system
          + Web-based view of disk space visualizer
          + papers spidered, recency, topics, co-authorship associations

********* Demos/Links to functionality


====================================================================================================
******* firefox plugins for rexa/spider interop
********* Overview
          Page view includes highlighted pdf links for which rexa has information
          Can submit page to rexa spider
          Can submit page text as auxililary infomation???
          Can get navigate via rexa directly from pdfs to other author pages
          Can search papers via rexa, with automatic limits to papers on page/domain/coauthored/etc...

********* Tasks
********* Feature wishlist
********* Demos/Links to functionality
====================================================================================================

******* Corpus Server (hybrid file based/mongodb/lucene pdf+ document retrieval)
********* Overview
          Corpus server/services
          + Managed files include pdfs and extracted text, tagged entities
          + Managed metadata includes user-supplied tags, annotations on pdfs
          + Retrieve cached pdfs, extracted text, and bibliographic mentions via web interface
          + Rsync server is used to shuttle files to and from other servers for processing (notably grid engine)
          + Mongodb is used to store tags, annotations, labels, ...
          + Lucene is used to index extracted tags, metadata (pstotext, metatagger)
          + Jetty is used to host web front-end, for searching and viewing corpus

********* Tasks
          - [-] Rsync functionality
            - [X] Sync working codebases across multiple machines
            - [X] Shuttle files to and from working nodes
            - [ ] Provide access to various resources and artifacts from pdfs
                - [ ] (maybe) multiple repos can cover on directory structure to expose different types of
                      files, e.g., rsync::/host/(pdfs|totest|crf|index|..)

          - [X] create a testbed corpus on which to run pipeline
          - [X] Create local-dev, remote-dev, remote-production setups
          - [ ] Write a script to check file/directory normalization
          - [ ] fabfile script can merge 2 directory structures
          - [ ] write script to kick off a processing task, defined
                as a host:sha-prefix or sha-hash, and kick off gamut

          - [ ] run pstotext, metatagger, and thumbnailer over corpus
          - [ ] Implement web-based search over text, metatags, w/thumbnails returned
          - [X] Mail-like file transfer protocol
          - [ ] Search over pdf/metatagged corpus
            - [ ] Put lucene (maybe) next to mongo and file corpus
            - [ ] aggregated search over corpora

          - [ ] make shards load-rebalanceable (in terms of # of docs, using rsync)
          - [ ] create a web interface for submitting pdfs and getting back pstotext/crf output
          - [ ] Web: # of Pdfs
          - [ ] Web: Searchable pdfs by URLs
          - [ ] Identify groups of files for processing, run in parallel

          + hierarchical structure of a normalized directory will define
            how search is handled:
            - q='machine learning'&tag='bibliography'&artifact='thumb'

====================================================================================================

******* Grep over corpus text output
********* Overview
          + A set of shell commands allows normal grepping over the text lines of the pdf corpus
          + The returned value is an id for the line, which can be piped into 'print' or 'show img'
            functions
          + Grep can be parameterized with a tagging spec, which associates groups in the regex with
            a label, e.g., /(@(\w.)+)/, {"\1": {label: email.tail}, "\2": {label: email.domain}}
          + search can be over line pairs, i.e., "... \n ...", in a sliding window fashion
          + A find function can select ranges and labels to restrict greps, e.g., find -n 10 -t
            "{label: email.tail}"
          + Labeling can be at page, line, region, or text span level of granularity (this needs
            more thinking)
          + Regex can be specified as 'unlabel' to remove prior labeling
********* Tasks
********* Feature wishlist
********* Demos/Links to functionality

====================================================================================================

******* Extract image/thumbs of front page, etc
        vertically aligned thumbs, one col/paper
        page and document-level annotations
             + run character-level segmentation on all images, collect all images that are roughly
               alphanumeric character sized, do some high precision clustering, and see how many
               clusters are created (too many for hand labeling?)
             + use known characters to bootstrap labeling process
             + Create a list of all papers for all conferences by year

******* Run pstotext/metatagger
        searchable by text
        html-like formatting of textual, metagged output
        overlay of text and image
        Hand alignment of text/images for headers/refs/acks/etc.

====================================================================================================

******* Task manager/iterator over pdfs, extracted text, mentions, etc
********* Overview
          Used as part of the Corpus Server.
          Task granularities:
            sha-hashed filename

            create a set of records in mongodb:
              file: {id, task_lock_id (-engid, 0=avail, 1=done)}


            ip>> (local) for f in corpus(): create_record({id, ...})
            ip>> (dist)  mec.run("for f in corpus(): ...")
            ip>> tc.run(pstotext, select({task_lock_id: 0}, 100))

====================================================================================================


******* (continue pipeline)
          - [*] Turn a set of pdfs into a set of mentions
              - [ ] fold in pstotext/gamut/crf projects
                    run using ipython (local)
                    run using ipython (from remote)

******* Entities include authors, papers, institutions, venues, years, topics


**** uncategorized:
     possible structure of an author's persistent label: pdf-sha1:page:bbox


* Current Directory Structures
            Mount           size  used  avail aval%
            /m/vinci5/data2 1.5T  636G  773G  46%
            /m/vinci5/data3 1.5T  1.3T  162G  89%
            /m/vinci7/data2 3.6T  3.1T  351G  90%
            /m/vinci7/data3 3.6T  331G  3.2T  10%
            /m/vinci8/data1 1.5T  1.4T   92G  94%
            /m/vinci9/data1 1.2T  659G  446G  60%


   /m/vinci5/
      (todo go get this data again...)

   /m/vinci7/
   :  |-- data2
   :  |   |-- rexa
   :  |   |   `-- corpus
   :  |   `-- saunders
   :  |       |-- acm-paperfiles
   :  |       |-- archive-just-in-case
   :  |       |-- hg-repo
   :  |       `-- rexa-dev-workspace
   :  `-- data3
   :      `-- rexa
   :          |-- local-configurations
   :          `-- mysql-data-dir
   : /vinci8
   :  `-- data1
   :      `-- saunders
   :          |-- mongodb
   :          `-- rexa-dev-workspace
   : /vinci9
   :  `-- data1
   :      |-- andresen
   :      |   `-- rexa-topicmodel
   :      |-- rexa
   :      |   |-- local-configurations
   :      |   `-- mysql-data-dir
   :      |-- rexo
   :      |   |-- database-backups
   :      |   `-- datasets
   :      `-- saunders
   :          |-- dev-mirror
   :          |-- heritrix-spidering
   :          |-- python
   :          |-- rexa-pipeline
   :          |-- sendak-backup
   :          |-- x-platform-share -> dev-mirror/x-platform-share
   :          `-- xorg

* annex

  pdoc = annex.load('p917-damian.pdf.d/pdfminer/p917-damian.pdf.pdfminer')
  annex.label(pdoc, r'1=refstart,lbracket 2=refmarker 3=rbracket 4=more', textre=r'^(\[)([^\]]+)(\])(.*)', multiline=7)
  print annex.format_labeled_doc(pdoc)


  - reformat output as single lines
    - allow tabstop-like alignment of fields based on regex and/or labels
  - restrict view to specified labels
  - render to graphical pane, with clickable/selectable regions
  - implement regex paintbrush
    - regex attached to pointer, such that matching lines are selected/tagged on mouseover


rxshell session example:
unsupervised clustering produces n-entities (..) (...)

> ls 1-10 => 01AF...,
> cat 01AF...
  [paper contents as imgs] [] [] []
> (drag-select an area like "[12]" to produce a regex-seed)
> rxgrep "\[[12]\]"
  means: find occurrances of clustered sequences for mention sequence '[12]''
  also: generate images of unicode codepoints in every known font and cluster those in the mix to provide a possible labelling
        use the output of ps2text for a given char mention to compare against the generated/clustered version
  terms - char mention: one of the segmented character images
          char entity: clustering of char mentions
          char codepoint: e.g., unicode-A, noise (perhaps?)
            (codepoint can be applied to a charmention, which means multiple codepoints
             can occur in a clustering, e.g., U and V, or '1' and 'l', in certain fonts,
             which are disambiguated by language modelling)


