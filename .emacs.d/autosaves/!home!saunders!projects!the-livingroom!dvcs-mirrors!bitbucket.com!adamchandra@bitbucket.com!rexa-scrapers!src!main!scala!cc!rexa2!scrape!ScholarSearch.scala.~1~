package cc.rexa2
package scrape

import java.io._
import org.xml.sax
import scala.xml._
import scalaz.{Scalaz => Z, _}
import scalaz.Scalaz.{node => _, _}



case class ScholarResultParse(
  scholarId: String, 
  title: String, 
  url: java.net.URI,
  numCitations: Int,
  numVersions: Int
)

class ScholarEndpoint { 
  import dispatch._

  val gschEndpoint = "scholar.google.com"

  val searcher = :/(gschEndpoint) / "scholar"

  /**
   * Read Html file as scala.xml.Node
   * (note: dispatch also has a module that does this,
   *  perhaps try that as alternative to the tagsoup lib)
   */
  def parseHtml(source: sax.InputSource): xml.Node = {
    val parserFactory = new org.ccil.cowan.tagsoup.jaxp.SAXFactoryImpl
    val parser = parserFactory.newSAXParser()
    val adapter = new scala.xml.parsing.NoBindingFactoryAdapter
    adapter.loadXML(source, parser)
  }

  def parseHtmlAsXml(s:String) = parseHtml(new sax.InputSource(new StringReader(s)))
  
  /**
   * dispatch http call/handler w/shutdown
   */
  def http[T](handler: => Handler[T]): T = {
    val h = new Http
    try { h(handler) }
    finally { h.shutdown() }
  }

  def formAllVersionsQuery(id: String) = List(
    "cluster"         -> id.toString,
    "hl"              -> "en"
  )

  def formKeywordQuery(terms: List[String]) = List(
    "q"                   -> terms.mkString("+"),
    "as_vis"              -> "1",
    "hl"                  -> "en",
    "as_sdt"              -> "1,22"
  )

  def formCitedByQuery(id: String) = List(
    "cites"               -> id.toString,
    "as_vis"              -> "1",
    "hl"                  -> "en",
    "oe"                  -> "ASCII",
    "as_sdt"              -> "40000005",
    "sciodt"              -> "1,22"
  )

  /**
   * Search scholar
   */
  def doSearch(query: Seq[(String, String)]): xml.Node = {
    http((searcher <<? query) >- { (response) => {
      parseHtmlAsXml(response)
    }})
  }

  /**
   * Search for papers w/given keywords
   */
  def keywordSearch(terms: List[String]): xml.Node = 
    doSearch(formKeywordQuery(terms))

  /**
   * Find all papers citing the paper returned by scholar,
   * using ID parsed from previous search results. Don't know
   * how stable those IDs are...
   */
  def citedBySearch(gsId: String): xml.Node = 
    doSearch(formCitedByQuery(gsId))

  /**
   * scholar wraps a  <div class="gs_r"> around each search
   * result. This selects just those nodes.
   */
  def selectGsRDivs(node:xml.Node): Seq[xml.Node] = for {
    div <- node \\ "div"
    cls <- div \ "@class" if cls.text == "gs_r"
  } yield div


  def stringToURI(s:String) = new java.net.URI(s)

  /**
   * break up /zz?a=b&c=d into Map(a->b, c->d)
   */
  def queryParamsToMap(qp:String):Map[String, String] = {
    (qp.split("&").toList.map(_.split("=").toList) map {
      case k :: v :: Nil => (k, v);
      case _ => sys.error("malformed params");
    }).toMap
  }


  def parseScholarEntry(div: xml.Node): Validation[String, ScholarResultParse] = {
    val title = { // parseTitle
      val parsed = for {
        titleh3 <- div \\ "h3"
        titleSpan <- titleh3 \ "@class" if titleSpan.text == "gs_rt"
      } yield {

      }
      
    }
    // val url = parseURL
    // both title/url must be present
    //val numCitation = parseNumCitations
    //val urlCitation = parseUrlCitation
    //val numVersion = parseNumVersions
    //val urlVersions = {}


    "todo".fail
  }


  def parseGsRDiv(div: xml.Node): Validation[String, ScholarResultParse] = {
    val parsed = for {
      a <- div \\ "a"
      href <- a \ "@href" if href.text.contains("cites=")
      titleh3 <- div \\ "h3"
      titleSpan <- titleh3 \ "@class" if titleSpan.text == "gs_rt"
      pdfUrl <- titleh3 \ "a"
      pdfHref <- pdfUrl \ "@href"
    } yield  {
      val hreft = href.text
      val query = stringToURI(hreft).getQuery()
      val params = queryParamsToMap(query)

      val gsId = params("cites")

      val digitsRE = "(\\d+)".r
      val citedCountOpt = digitsRE.findFirstIn(a.text).map(_.toInt.right)
      

      val res = ScholarResultParse(
        scholarId = gsId,
        title = titleh3.text,
        url = new java.net.URI(pdfHref.text),
        numCitations = 0,
        numVersions = 0
      )
      res
    }
    parsed.headOption map (_.success) getOrElse "could not parse div".fail
  }

  def filterAndParseResults(gsResults:xml.Node): Seq[Validation[String, ScholarResultParse]] = {
    // filter results to just the interesting divs
    val divNodes = selectGsRDivs(gsResults)
    // try to parse out information (citedBy counts, id, title, ...)
    divNodes map (parseGsRDiv(_))
  }


  def search(terms: List[String]) {
    // find papers by keyword
    val htmlNodes = keywordSearch(terms)

    val parses = filterAndParseResults(htmlNodes)

    // issue another query for papers that cite the parsed papers
    val citing = for {
      vp <- parses
    } yield {
      vp map (p => citedBySearch(p.scholarId))
    }
    // ... and parse those in turn...
    val parsed = citing map (c => for {
      p <- c
    } yield {
      val sd  = selectGsRDivs(p)
      sd map (parseGsRDiv(_))
    })
  }
}

